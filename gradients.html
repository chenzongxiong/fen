<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2019-04-29 Mon 09:42 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>&lrm;</title>
<meta name="generator" content="Org mode" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2018 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org07f86d9">1. formula</a></li>
<li><a href="#org6dec04f">2. RNN gradients</a></li>
<li><a href="#org48efe02">3. Implementation</a></li>
<li><a href="#org3525ec4">4. Trading</a></li>
<li><a href="#org3a0d5e3">5. Direct Learning</a></li>
<li><a href="#org0aef3ea">6. MSE and MLE</a></li>
<li><a href="#org44776f5">7. How to determine undetermined direction of random walk ?</a></li>
</ul>
</div>
</div>
<div id="outline-container-org07f86d9" class="outline-2">
<h2 id="org07f86d9"><span class="section-number-2">1</span> formula</h2>
<div class="outline-text-2" id="text-1">
<p>
First we only consider <b>one play</b>
</p>
\begin{eqnarray}
G(P_{n}, w^{1}) = \sum_{i=1}^{S} \tilde{\theta_{i}} \tanh(\theta_{i} P_{n} + \theta_{i0}) + \tilde{\theta_{0}}
\end{eqnarray}

<p>
Where \(P_{n} = [p_{1}, p_{2}, p_{3}, ..., p_{n}]\), \(G(P_{n}, w^{1}) = [y_{1}, y_{2}, y_{3}, ..., y_{n}]\)
</p>

<p>
\(\forall{i} \in [1, ..., S]\), \(\theta_{i} P_{n} = (\theta_{i} p_{1}, \theta_{i} p_{2}, \theta_{i} p_{3}, ..., \theta_{i} p_{n})\),
</p>

<p>
So
\(\tanh(\theta_{i} P_{n} + \theta_{i0}) =
[\tanh(\theta_{i} p_{1} + \theta_{i0}),
\tanh(\theta_{i} p_{2} + \theta_{i0}),
\tanh(\theta_{i} p_{3} + \theta_{i0}),
...,
\tanh(\theta_{i} p_{n} + \theta_{i0})]\)
</p>

<p>
So \(\sum_{i=1}^{S} \tilde{\theta_{i}} \tanh(\theta_{i} P_{n} + \theta_{i0}) + \tilde{\theta_{0}} =
[\sum_{i=1}^{S} \tilde{\theta_{i}} \tanh(\theta_{i} p_{1} + \theta_{i0}) + \tilde{\theta_{0}},
\sum_{i=1}^{S} \tilde{\theta_{i}} \tanh(\theta_{i} p_{2} + \theta_{i0}) + \tilde{\theta_{0}},
...,
\sum_{i=1}^{S} \tilde{\theta_{i}} \tanh(\theta_{i} p_{n} + \theta_{i0}) + \tilde{\theta_{0}}] =
[y_{1}, y_{2}, ..., y_{n}]\).
</p>

<p>
Take \(y_{j}\), where \(j \in [1, ..., n]\) for example
</p>

<p>
Let \(z_{i, j}=\theta_i p_j + \theta_{i0}\) and \(f(z_{i, j}) = \tanh(\theta_i p_j + \theta_{i0})\), we obtain
</p>
\begin{eqnarray}
y_{j}  &=& \sum_{i=1}^{S} \tilde{\theta_{i}} \tanh(\theta_{i} p_{j} + \theta_{i0}) + \tilde{\theta_{0}}  \\
       &=& \sum_{i=1}^{S} \tilde{\theta_{i}} f(z_{i, j}) + \tilde{\theta_{i0}}
\end{eqnarray}

<p>
Calculate derivation for \(y_{j}\),
</p>
\begin{eqnarray}
\frac{\partial y_{j}}{\partial p_{j}} &=& \sum_{i=1}^{S} \tilde{\theta_{i}} \theta_{i} \frac{\partial f(z_{i, j})}{\partial z_{i, j}}
\end{eqnarray}

<p>
Now let's consider the mapping between \(p_{j}\) and \(x_{j}\). let \(\sigma_{j} = w^{1} x_{j} - p_{j-1}\)
</p>
\begin{eqnarray}
p_{j} = \Phi(\sigma_{j}) + p_{j-1}
\end{eqnarray}

<p>
and
</p>

\begin{eqnarray}
\Phi(x) =
        \begin{cases}
        x - 1/2, & x > 1/2 \\
        0, & -1/2 < x < -1/2 \\
        x + 1/2, & x < -1/2 \\
        \end{cases}
\end{eqnarray}

\begin{eqnarray}
\Phi(x) =
        \begin{cases}
        x + 1/2, & x > 1/2 \\
        0, & -1/2 < x < -1/2 \\
        x - 1/2, & x < -1/2 \\
        \end{cases}
\end{eqnarray}


<p>
Using chain rule, we obtain
</p>
\begin{eqnarray}
\frac{\partial y_{j}}{\partial x_{j}} &=& \frac{\partial y_{j}}{\partial p_{j}} \frac{\partial p_{j}}{\partial x_{j}} \\
                                      &=& \sum_{i=1}^{S} \tilde{\theta_{i}} \theta_{i} w^{1} \frac{\partial f(z_{i, j})}{\partial z_{i, j}} \frac{\partial{\Phi(\sigma_{j})}}{\partial{\sigma_{j}}}
\end{eqnarray}


<p>
To consider <b>multiple plays</b> case, we reformulate the derivation as following:
</p>

\begin{eqnarray}
\frac{\partial {y_{j}^{1}}}{\partial x_{j}} &=& \frac{\partial{y_{j}^{1}}}{\partial{p_{j}^{1}}} \frac{\partial{ p_{j}}^{1}}{\partial x_{j}} \\
                                      &=& \sum_{i=1}^{S} \tilde{\theta_{i}^{1}} \theta_{i}^{1} w^{1} \frac{\partial f(z_{i, j}^{1})}{\partial z_{i, j}^{1}} \frac{\partial{\Phi(\sigma_{j}^{1})}}{\partial{\sigma_{j}^{1}}}
\end{eqnarray}


<p>
Now from the architecture, we know that if we have \(P\) plays,
</p>
\begin{eqnarray}
F = \frac{1}{P} \sum_{k=1}^{P} G^{k}
\end{eqnarray}
<p>
Where \(F=[f_1, f_2, ..., f_n]\),
and
</p>
\begin{eqnarray}
f_{j} = \frac{1}{P} \sum_{k=1}^{P} y_{j}^{k}
\end{eqnarray}

<p>
our derivation is:
</p>

\begin{eqnarray}
\frac{\partial f_{j}}{\partial x_{j}} &=& \frac{1}{P} \sum_{k=1}^{P} \frac{\partial {{y_{j}^{k}}}}{\partial {{x_{j}}}} \\
               &=& \frac{1}{P} \sum_{k=1}^{P} \frac{\partial {y_{j}^{k}}}{\partial {p_{j}^{k}}} \frac{\partial {p_{j}^{k}}}{\partial {x_{j}}} \\
               &=& \frac{1}{P} \sum_{k=1}^{P}  \sum_{i=1}^{S} \tilde{\theta_{i}^{k}} \theta_{i}^{k} w^{k} \frac{\partial f(z_{i, j}^{k})}{\partial z_{i, j}^{k}} \frac{\partial{\Phi(\sigma_{j}^{k})}}{\partial{\sigma_{j}^{k}}}
\end{eqnarray}
</div>
</div>

<div id="outline-container-org6dec04f" class="outline-2">
<h2 id="org6dec04f"><span class="section-number-2">2</span> RNN gradients</h2>
<div class="outline-text-2" id="text-2">
\begin{eqnarray}
\frac{\partial p_j}{\partial x_j} &=& \Phi'(\sigma_j) \frac{\partial \sigma_j}{\partial x_j} \\
&=& \Phi'(\sigma_j) w^{1} \\
\\
\\
\frac{\partial p_{j+1}}{\partial x_j} &=& \frac{\partial (\Phi(\sigma_{j+1}) + p_j)}{\partial x_j} \\
&=& \Phi'(\sigma_{j+1}) \frac{\partial \sigma_{j+1}}{\partial x_j} + \frac{\partial p_j}{\partial x_j} \\
&=& \Phi'(\sigma_{j+1}) \frac{\partial (w^{1} x_{j+1} - p_{j})}{\partial x_j} + \frac{\partial p_j}{\partial x_j} \\
&=& (1-\Phi'(\sigma_{j+1})) \Phi'(\sigma_j) w^{1} \\
\\
\\
\frac{\partial p_{j+2}}{\partial x_j} &=&  (1-\Phi'(\sigma_{j+2})) (1-\Phi'(\sigma_{j+1})) \Phi'(\sigma_j) w^{1} \\
\\
\\
\frac{\partial p_{j+i}}{\partial x_j} &=&  (1-\Phi'(\sigma_{j+i})) ... (1-\Phi'(\sigma_{j+1})) \Phi'(\sigma_j) w^{1}
\end{eqnarray}
</div>
</div>

<div id="outline-container-org48efe02" class="outline-2">
<h2 id="org48efe02"><span class="section-number-2">3</span> Implementation</h2>
<div class="outline-text-2" id="text-3">
<p>
Consider \(\mathcal{P}_{n} = [p_{1}, p_{2}, p_{3}, ..., p_{n}]\), \(G(\mathcal{P}_{n}, w^{1}) = [y_{1}, y_{2}, y_{3}, ..., y_{n}]\)
</p>
</div>
</div>

<div id="outline-container-org3525ec4" class="outline-2">
<h2 id="org3525ec4"><span class="section-number-2">4</span> Trading</h2>
<div class="outline-text-2" id="text-4">
<p>
Assume, we observe prices \(p_1, p_2, ..., p_N\) for a fixed \(N > 0\). Based on Dima's paper,
assume that the price \(p_{n}\) hysteretically depends on the underlying noise \(b_n\), with \(b_n\) being a
Brownian motion. Using the notation
</p>

<p>
\[\mathcal{B}_n := (b_1, b_2, ..., b_n), \mathcal{P}_n := (p_1, p_2, ..., p_n)\]
</p>

<p>
we have
</p>
\begin{eqnarray}
b_{0} = 0, \, b_{n} \thicksim \mathcal{N} (b_{n-1} + \mu_{b}, \sigma_{b}) \\
p_{n} = F(\mathcal{B}_n, W_{p})
\end{eqnarray}


<p>
Based on Dima's paperr again, the underlying noise \(b_n\) can be expressed as a hysteresis operator depending on
the observed prices \(p_n\), i.e.,
\[b_n=G(\mathcal{P}_n, W_b)\]
</p>


<p>
**This is very nice as long as F and G are Prandtl-Ishlinskii operators. However, if one explicitly adds N's strategy,
G becomes Preisach and F is not Preisach anymore. It is not clear how well it can be approximated by compositions of
plays and nonlinear functions**
</p>
</div>
</div>


<div id="outline-container-org3a0d5e3" class="outline-2">
<h2 id="org3a0d5e3"><span class="section-number-2">5</span> Direct Learning</h2>
<div class="outline-text-2" id="text-5">
<p>
We learn the parameters \(W_b, \mu_b, \sigma_b\) and the initial state \(p_0\) of the network \(G\) by maximizing
the likelihood of \(\mathcal{P}\). Since \(\mathcal{P}\) is the determenistic function of a random variable
\(mathcal{B}\), its probability density is given by
</p>

\begin{eqnarray}
p(\mathcal{P}) &=& p(p_1, p_2, ..., p_N) \\
               &=& p_b(b_1, b_2, ..., b_N) \left|\det \mathcal{J(P)}\right| \\
               &=& p_b(G(\mathcal{P}_1, W_b), G(\mathcal{P}_2, W_b), ..., G(\mathcal{P}_N, W_b)) \left|\det \mathcal{J(P)}\right|
\end{eqnarray}

<p>
where
</p>
\begin{eqnarray}
p_b({\mathcal{B}}) &=& \prod_{n=1}^{N} p_b(b_1, b_2, ..., b_N) \\
                   &=& \prod_{n=1}^{N} p_b(b_n|b_{n-1}) \\
                   &=& \prod_{n=1}^{N} \frac{1}{\sqrt{2 \pi} \sigma} \exp\left(-\frac{(b_{n}-b_{n-1}-\mu_{b})^2}{2 \sigma^2}\right)
\end{eqnarray}
<p>
is the probability distribution of \(\mathcal{B}\) and \(\mathcal{J(P)}\) is the Jacobian matrix. Recall that \(G\) has the
causality property, hence \(\mathcal{J(P)}\) is a triangular matrix. Therefore, yield
</p>
\begin{eqnarray}
p(\mathcal{P}) &=& p_b(G(\mathcal{P}_1, W_b), G(\mathcal{P}_2, W_b), ..., G(\mathcal{P}_N, W_b)) \left|\det \mathcal{J(P)}\right| \\
               &=& \prod_{n=1}^{N} \frac{1}{\sqrt{2 \pi} \sigma} \exp\left(-\frac{(b_{n}-b_{n-1}-\mu_{b})^2}{2 \sigma^2}\right)
                   \prod_{n=1}^{N} \left| \frac{\partial b_n}{\partial p_n} \right| \\
               &=& \prod_{n=1}^{N} \frac{1}{\sqrt{2 \pi} \sigma} \exp\left(-\frac{(b_{n}-b_{n-1}-\mu_{b})^2}{2 \sigma^2}\right) \left|\frac{\partial b_n}{\partial p_n}\right|
\end{eqnarray}

<p>
Thus, maximizing the log-likelihood of \(p(\mathcal{P})\) is equivalent to the following:
</p>
\begin{eqnarray}
L = \ln p(\mathcal{P}) &\thicksim& \sum_{n=1}^{N} \left(- \frac{(b_n-b_{n-1}-\mu_{b})^2}{2 \sigma_{b}^2} - \ln \sigma_{b} + \ln \left|\frac{\partial b_n}{\partial p_n}\right|\right) \\
  &=& - \frac{1}{2} \sum_{n=1}^{N} \left[\left(\frac{b_n - b_{n-1} - \mu_{b}}{\sigma_b} \right)^2 + 2 \ln \sigma_{b} - 2 \ln \left|\frac{\partial b_n}{\partial p_n}\right|\right]
\end{eqnarray}

<p>
It's also equivalent to minimize the loss function as following:
</p>
\begin{eqnarray}
\min_{W_b, p_0} L &=& \min_{W_b, p_0} \sum_{n=1}^{N} \left[\left(\frac{b_n - b_{n-1} - \mu_{b}}{\sigma_b} \right)^2 - 2 \ln \left|\frac{\partial b_n}{\partial p_n}\right|\right] \\
       &=& \min_{W_b, p_0} \sum_{n=1}^{N} \left[\left( b_n - b_{n-1} - \mu_{b}\right)^2 - 2 \sigma_{b}^2 \ln \left|\frac{\partial b_n}{\partial p_n}\right|\right]
\end{eqnarray}

<p>
From the target loss function, the only parameters we need to known is \(\mu_b\).
</p>


<p>
Consider second part of loss function, \(\ln \frac{\partial b_{n}}{\partial p_{n}}\), we reformulate it to \(\ln \frac{\partial f_{j}}{\partial x_{j}} = \ln h_{j}\)
</p>

\begin{eqnarray}
\frac{ \partial \ln h_j}{\partial w^{k}} &=& \frac{1}{h_j} * \frac{\partial h_j} { \partial w^k}
\end{eqnarray}
</div>
</div>

<div id="outline-container-org0aef3ea" class="outline-2">
<h2 id="org0aef3ea"><span class="section-number-2">6</span> MSE and MLE</h2>
<div class="outline-text-2" id="text-6">
\begin{eqnarray}
y &\thicksim& \mathcal{N} \left( y | G(x, w), \sigma^2 \right)
\end{eqnarray}

\begin{eqnarray}
p(y) &=& \frac{1}{\sqrt{2 \pi} \sigma} \exp \left(-\frac{(y-G(x, w))^2}{\sigma^2} \right)
\end{eqnarray}

\begin{eqnarray}
p(\mathcal{Y}) &=& p (y_1, y_2, ..., y_N) \\
               &=& \prod_{i}^N p(y_i)
\end{eqnarray}

\begin{eqnarray}
\ln p(\mathcal{Y}) &=& \sum_{i} \left( -\frac{1}{2}\ln 2 \pi - \ln \sigma - \frac{(y_i - G(x_i, w)^2}{\sigma^2} \right)
\end{eqnarray}

<p>
Assume \(z_i = f(y_i)\), we obtain
</p>
\begin{eqnarray}
p(z_i) = p(f(y_i)) \left(\frac{\partial f}{\partial y_i}\right)^{-1} f^{-1}(z_i)
\end{eqnarray}
<p>
\(\max (\mu, \sigma, w)\) s.t. \(p(z_i)\) is maximal
</p>
</div>
</div>

<div id="outline-container-org44776f5" class="outline-2">
<h2 id="org44776f5"><span class="section-number-2">7</span> How to determine undetermined direction of random walk ?</h2>
<div class="outline-text-2" id="text-7">
<p>
If external agents buy stocks from the market, then the total number of stocks in market descreases, leading to increasing the prices.
</p>

<p>
In other words, the amount of stocks in market descreases if price rises. And the amount of stocks increases if prices go down.
</p>

<p>
The root cause of amount chaging in our assumption is the behavior of external agents.
We model the behavior of external agents as markov chain(random walk).
</p>

<p>
Since we observe a series of prices in advance, we can determine the direction of random walk.
</p>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="date">Created: 2019-04-29 Mon 09:42</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
